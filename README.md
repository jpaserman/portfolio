# Data Science Portfolio

## üõ†Ô∏è Technical Skills
- **Languages & Tools:** Python, R, SQL, Stata  
- **Core Expertise:** Machine Learning, Artificial Intelligence, Statistical Analysis, Distributed Computing  

---

## üéì Education
- **M.Sc. Data Science** ‚Äî The London School of Economics and Political Science (September 2025)  
- **B.A. Economics & Mathematics** ‚Äî Boston University (May 2022)  

---

## üìÇ Projects


### Dimensionality Reduction in Single-Cell RNA Sequencing Data
Capstone project with the Wellcome Sanger Institute, University of Cambridge. Applied machine learning techniques for dimensionality reduction in high-dimensional single-cell RNA sequencing data. Developed a dimensionality reduction and clustering pipeline to characterize cell-type heterogeneity. I helped identify subtle transcriptional signatures using a combination of linear and non-linear methods (PCA, UMAP, t-SNE), along with other Deep Learning data integration techniques (scVI, scanorama, Harmony, BBKNN, etc.), and other unsupervised clustering and differential expression analysis. 

### Change Our View: A Distributed Topic Modelling Study of Persuasion Dynamics in r/ChangeMyView
[Research Report]() | [GitHub Repo]()  

This research explored persuasion dynamics in the r/ChangeMyView subreddit using distributed computing and natural language processing techniques. The project involved building scalable data pipelines in PySpark to process large-scale Reddit discussion data, implementing distributed topic modeling algorithms to identify patterns in successful persuasion attempts, and engineering features to predict when users would award "deltas" (indicating a changed view). We analyzed millions of comments to understand what linguistic and structural features make arguments more persuasive in online discourse. Through this work, I developed expertise in distributed computing frameworks, large-scale text analysis, and applying machine learning to understand human communication patterns.

### Locating Bacterial Flagellar Motors in 3D Tomogram Data
[Research Report]() | [GitHub Repo]()  

This project addressed the challenge of automatically detecting and localizing bacterial flagellar motors in three-dimensional cryo-electron tomogram data. Working with noisy, low-contrast 3D imaging data, I developed and compared multiple approaches ranging from custom convolutional neural network (CNN) architectures to state-of-the-art object detection models. The project began with a custom PyTorch CNN for direct coordinate regression, and later expanded to include evaluations of YOLO variants (YOLOv8n, YOLOv8m, YOLOv11m) and RT-DETR models. I designed a preprocessing pipeline that extracted 2D slices from 3D tomograms with percentile-based normalization, implemented data augmentation strategies to account for orientation variation and occlusion, and performed systematic performance comparisons using mean Euclidean distance and F-2 scores. This work provided valuable insights into the application of modern computer vision techniques to challenging biological imaging problems, particularly in contexts with low signal-to-noise ratios and small object detection requirements.


### Evaluating Classical Artificial Intelligence Algorithms on Connect Four
[Research Report]() | [GitHub Repo](https://github.com/pholmes116/connect-four-ai-public.git)  

This research involved implementing and comparing three classical AI algorithms for Connect Four: Monte Carlo Tree Search, Alpha-Beta Pruning, and Alpha-Beta Pruning with a heuristic evaluation function. After hyperparameter tuning on the standard 7x6 board, we tested the algorithms in tournaments that included rule variations such as larger and smaller boards, a three-player setup, and the introduction of blocker stones. These modifications allowed us to evaluate how each approach balanced win rate and computational efficiency across increasingly complex environments. Results showed that while Monte Carlo Tree Search performed well with large branching factors, Alpha-Beta with evaluation was the most consistent and adaptable agent overall. Through this project, I gained experience in implementing game-tree search algorithms, designing controlled experiments for AI evaluation, and analyzing the trade-offs between accuracy, efficiency, and adaptability in algorithmic decision-making.

---

## Work Experience

### AIVF ‚Äî Tel Aviv, Israel  
**Data Analyst / Data Engineer | September 2022 ‚Äì September 2024**  

At AIVF, a startup dedicated to advancing AI-powered IVF solutions, I developed analytical solutions to improve both patient outcomes and clinical operations. I conducted statistical analysis in Python to assess proprietary algorithms designed to improve pregnancy outcomes, leading the statistical evaluation that demonstrated embryos in the top predicted tier had pregnancy success rates exceeding 50%‚Äîa critical validation of the model‚Äôs clinical impact. Additionally, I built an automated data pipeline using Python and AWS that migrated Electronic Medical Record (EMR) data from IVF clinics into standardized formats and databases. This automation directly enabled the recruitment of five international clinic clients by significantly improving operational efficiency. Through this role, I gained extensive experience in healthcare data engineering, statistical validation of machine learning models in clinical settings, and building scalable cloud-based infrastructure.

### Federal Reserve Bank of Boston ‚Äî Boston, USA  
**Research Intern for Principal Economist and Policy Advisor | May 2021 ‚Äì May 2022**  

At the Federal Reserve Bank of Boston, I supported research on financial economics, monetary policy, and international trade. My work included extensive data collection and cleaning, the development of econometric models, and the creation of visualizations in Stata to support peer-reviewed publications. I collaborated on three major research projects focusing on multinational mergers and acquisitions, global banking shocks, and commercial real estate lending. This experience provided rigorous training in applied economic research methods, working with large and complex financial datasets, and contributing to policy-relevant analysis within a major financial institution.

---
